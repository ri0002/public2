# -*- coding: utf-8 -*-
"""第8回_二項分類の推定プログラム_g241tg2002_石川遼太郎

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PI0NcklExXxh2ih4ggF1Ul3bzRFJf6mX
"""

import pandas as pd
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, roc_auc_score, precision_score, recall_score, f1_score
import os


# データの読み込み関数
def load_and_sample_data(file_path, sample_size=20000):
    """
    データを読み込み、サンプリングを実施する。
    Args:
        file_path (str): データファイルのパス。
        sample_size (int): サンプルのサイズ。

    Returns:
        pd.DataFrame: サンプリングされたデータ。
    """
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"指定されたファイルが見つかりません: {file_path}")

    try:
        data = pd.read_csv(file_path)
        return data.sample(n=sample_size, random_state=42)
    except Exception as e:
        raise ValueError(f"データの読み込みに失敗しました: {e}")


# データの前処理関数
def preprocess_data(data, target_column, drop_columns):
    """
    データの前処理（特徴量とラベルの分離、標準化）を行う。
    Args:
        data (pd.DataFrame): 元のデータ。
        target_column (str): 目的変数の列名。
        drop_columns (list): 除外する列名のリスト。

    Returns:
        tuple: (特徴量, ラベル) のタプル
    """
    X = data.drop(columns=drop_columns)
    y = data[target_column]
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    return X_scaled, y


# ランダムフォレストのハイパーパラメータチューニング関数（高速化版）
def tune_random_forest(X_train, y_train):
    """
    ランダムフォレストのハイパーパラメータをランダムサーチでチューニング。
    Args:
        X_train: トレーニングデータ（特徴量）。
        y_train: トレーニングデータ（ラベル）。

    Returns:
        RandomForestClassifier: 最適なモデル。
    """
    param_dist = {
        'n_estimators': [50, 100, 150],
        'max_depth': [5, 10, 15],
        'min_samples_split': [2, 5, 10],
    }
    random_search = RandomizedSearchCV(
        RandomForestClassifier(random_state=42),
        param_distributions=param_dist,
        n_iter=10,  # 試行回数を10に制限
        cv=3,       # クロスバリデーションの分割数
        scoring='roc_auc',
        n_jobs=-1,  # 並列処理を有効化
        random_state=42
    )
    random_search.fit(X_train, y_train)
    print(f"Best Parameters for Random Forest: {random_search.best_params_}")
    return random_search.best_estimator_


# モデルのトレーニングと評価関数
def train_and_evaluate_model(X_train, X_test, y_train, y_test, model):
    """
    モデルをトレーニングし、評価する。
    Args:
        X_train, X_test: トレーニングとテストデータ（特徴量）。
        y_train, y_test: トレーニングとテストデータ（ラベル）。
        model: 学習させるモデル。

    Returns:
        dict: 評価結果（Classification Report, ROC AUC, Accuracy, Precision, Recall, F1 Score）
    """
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]

    return {
        "classification_report": classification_report(y_test, y_pred),
        "roc_auc": roc_auc_score(y_test, y_pred_proba),
        "accuracy": model.score(X_test, y_test),
        "precision": precision_score(y_test, y_pred),
        "recall": recall_score(y_test, y_pred),
        "f1_score": f1_score(y_test, y_pred),
    }


# メイン処理
def main():
    # ファイルのパス
    file_path = '/content/creditcard.csv'

    try:
        # データの読み込みとサンプリング（サイズを減らす）
        sampled_data = load_and_sample_data(file_path, sample_size=20000)

        # データの前処理
        drop_columns = ['class', 'Time']
        X, y = preprocess_data(sampled_data, target_column='class', drop_columns=drop_columns)

        # トレーニングデータとテストデータに分割
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.4, random_state=42, stratify=y
        )

        # ランダムフォレストのハイパーパラメータチューニング
        rf_model = tune_random_forest(X_train, y_train)
        rf_results = train_and_evaluate_model(X_train, X_test, y_train, y_test, rf_model)

        # ロジスティック回帰でモデル構築と評価
        lr_model = LogisticRegression(random_state=42, max_iter=1000)
        lr_results = train_and_evaluate_model(X_train, X_test, y_train, y_test, lr_model)

        # 結果の表示
        print("=== Random Forest Results ===")
        print(rf_results["classification_report"])
        print(f"ROC AUC: {rf_results['roc_auc']:.4f}")
        print(f"Accuracy: {rf_results['accuracy']:.4f}")
        print(f"Precision: {rf_results['precision']:.4f}")
        print(f"Recall: {rf_results['recall']:.4f}")
        print(f"F1 Score: {rf_results['f1_score']:.4f}")

        print("\n=== Logistic Regression Results ===")
        print(lr_results["classification_report"])
        print(f"ROC AUC: {lr_results['roc_auc']:.4f}")
        print(f"Accuracy: {lr_results['accuracy']:.4f}")
        print(f"Precision: {lr_results['precision']:.4f}")
        print(f"Recall: {lr_results['recall']:.4f}")
        print(f"F1 Score: {lr_results['f1_score']:.4f}")

    except Exception as e:
        print(f"エラーが発生しました: {e}")


if __name__ == "__main__":
    main()